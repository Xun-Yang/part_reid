{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_type='detected'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_cuhk03_dict(DATA_DIR='../../dataset/cuhk03/cuhk03_release/'):\n",
    "    set_no = 1\n",
    "    phase = 'train'\n",
    "    filename_train = DATA_DIR + 'exp_set/set%02d_%s_noval.txt'%((set_no),phase)\n",
    "    print filename_train\n",
    "\n",
    "    file_object = open(filename_train)\n",
    "    try:\n",
    "        all_the_text = file_object.read( )\n",
    "    finally:\n",
    "        file_object.close( )\n",
    "\n",
    "    lines = all_the_text.split('\\n')\n",
    "    new_lines = []\n",
    "    for filename in lines:\n",
    "        if filename!='' :\n",
    "            campair_no = int(filename.split(',')[0])\n",
    "            person_id = int(filename.split(',')[1])\n",
    "            if campair_no<=3: \n",
    "                new_lines.append(filename)\n",
    "    \n",
    "    all_id_dict={}\n",
    "    for filename in new_lines:\n",
    "        if filename!='' :\n",
    "            campair_no = int(filename.split(',')[0])\n",
    "            person_id = int(filename.split(',')[1])\n",
    "            #print int(campair_no)\n",
    "            for img_no in range(10):\n",
    "                this_filename = DATA_DIR +  data_type+'/campair_%d/'%campair_no + '%02d_%04d_%02d.jpg'%(campair_no,person_id,img_no+1)\n",
    "                global_person_id=campair_no*10000+person_id\n",
    "                if os.path.isfile(this_filename):\n",
    "                    if all_id_dict.has_key(global_person_id):\n",
    "                        all_id_dict[global_person_id].append(this_filename)\n",
    "                    else:\n",
    "                        all_id_dict[global_person_id]=[this_filename]\n",
    "    #shuffle\n",
    "    id_list=all_id_dict.keys()\n",
    "    print len(id_list)\n",
    "    return all_id_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../dataset/cuhk03/cuhk03_release/exp_set/set01_train_noval.txt\n",
      "1260\n"
     ]
    }
   ],
   "source": [
    "all_id_dict=get_cuhk03_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./train_list/train.txt\n",
      "../../dataset/cuhk03/cuhk03_release/exp_set/set01_train_noval.txt\n",
      "1260\n",
      "total train samples:25200000\n",
      "./train_list/test.txt\n",
      "../../dataset/cuhk03/cuhk03_release/exp_set/set01_test_noval.txt\n",
      "100\n",
      "total test samples:1000\n"
     ]
    }
   ],
   "source": [
    "set_no = 1\n",
    "target_path = './train_list/'\n",
    "imdb_save_path=target_path\n",
    "\n",
    "if not os.path.exists(imdb_save_path):\n",
    "    os.makedirs(imdb_save_path)\n",
    "    \n",
    "DATA_DIR= '../../dataset/cuhk03/cuhk03_release/'\n",
    "\n",
    "#crop to 160x80\n",
    "M=160   #height\n",
    "N=80   #width\n",
    "\n",
    "\n",
    "shuffle_times=2000\n",
    "for conf_no in range(2):\n",
    "    if conf_no==0:\n",
    "        list_name = target_path+'train.txt'\n",
    "        phase = 'train'\n",
    "    else:\n",
    "        list_name = target_path+'test.txt'\n",
    "        shuffle_times=1\n",
    "        phase = 'test'\n",
    "\n",
    "    print list_name\n",
    "\n",
    "    filename_train = DATA_DIR + 'exp_set/set%02d_%s_noval.txt'%((set_no),phase)\n",
    "    print filename_train\n",
    "\n",
    "    file_object = open(filename_train)\n",
    "    try:\n",
    "        all_the_text = file_object.read( )\n",
    "    finally:\n",
    "        file_object.close( )\n",
    "\n",
    "    lines = all_the_text.split('\\n')\n",
    "    new_lines = []\n",
    "    for filename in lines:\n",
    "        if filename!='' :\n",
    "            campair_no = int(filename.split(',')[0])\n",
    "            person_id = int(filename.split(',')[1])\n",
    "            if campair_no<=3: \n",
    "                new_lines.append(filename)\n",
    "    \n",
    "    all_id_dict={}\n",
    "    for filename in new_lines:\n",
    "        if filename!='' :\n",
    "            campair_no = int(filename.split(',')[0])\n",
    "            person_id = int(filename.split(',')[1])\n",
    "            #print int(campair_no)\n",
    "            for img_no in range(10):\n",
    "                this_filename = DATA_DIR +  data_type+'/campair_%d/'%campair_no + '%02d_%04d_%02d.jpg'%(campair_no,person_id,img_no+1)\n",
    "                global_person_id=campair_no*10000+person_id\n",
    "                if os.path.isfile(this_filename):\n",
    "                    if all_id_dict.has_key(global_person_id):\n",
    "                        all_id_dict[global_person_id].append(this_filename)\n",
    "                    else:\n",
    "                        all_id_dict[global_person_id]=[this_filename]\n",
    "    #shuffle\n",
    "    id_list=all_id_dict.keys()\n",
    "    print len(id_list)\n",
    "    image_list=[]\n",
    "    person_id_list=[]\n",
    "    for shuffle_idx in range(shuffle_times):\n",
    "        if shuffle_idx>0:\n",
    "            random.shuffle(id_list)\n",
    "        for person_id in id_list:\n",
    "            filename_lists=all_id_dict[person_id]\n",
    "            for filename in filename_lists:\n",
    "                idx=filename[:filename.rfind('/')].rfind('/')\n",
    "                image_name=filename[idx+1:]\n",
    "                image_list.append(image_name)\n",
    "                person_id_list.append(person_id)\n",
    "    fid=open(list_name,'w')\n",
    "    for image_idx in range(len(image_list)):\n",
    "        fid.write(image_list[image_idx]+' '+str(person_id_list[image_idx])+'\\n')\n",
    "    fid.close()\n",
    "    print \"total \"+phase+\" samples:\" + str(len(image_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
